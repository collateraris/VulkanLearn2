#version 460
#extension GL_EXT_ray_tracing : require
#extension GL_EXT_nonuniform_qualifier:enable
#extension GL_GOOGLE_include_directive : enable

#include "gi_raytrace.h"

layout(location = 0) rayPayloadEXT IndirectRayPayload indirectRpl;
layout(location = 1) rayPayloadEXT AORayPayload aoRpl;

layout(set = 0, binding = 1) uniform sampler2D texSet[];
layout(set = 0, binding = 2) uniform accelerationStructureEXT topLevelAS;

layout(set = 1, binding = 0) uniform _GlobalGIParams { SGlobalGIParams giParams; };

layout(set = 1, binding = 1) readonly buffer _Lights{

	SLight lights[];
} lightsBuffer;

layout(set = 1, binding = 2) readonly buffer ObjectBuffer{

	SObjectData objects[];
} objectBuffer;

layout(set = 2, binding = 0) uniform sampler2D reservoirPrev;
layout(set = 2, binding = 1, rgba32f) uniform image2D reservoirCurr;
layout(set = 2, binding = 2, rgba32f) uniform image2D indirectOutput;

layout(set = 3, binding = 0) uniform samplerCube irradianceMap;
layout(set = 3, binding = 1) uniform samplerCube prefilteredMap;
layout(set = 3, binding = 2) uniform sampler2D   brdfLUT;


#include "gi_raytrace_func.h"

void main() 
{
    const vec2 uv = vec2(gl_LaunchIDEXT.xy)/vec2(gl_LaunchSizeEXT.xy);
    const vec2 pixelCenter = vec2(gl_LaunchIDEXT.xy) + vec2(0.5);
    const vec2 inUV = pixelCenter/vec2(gl_LaunchSizeEXT.xy);
    vec2 d = inUV * 2.0 - 1.0;
    
    vec4 origin    = giParams.viewInverse * vec4(0, 0, 0, 1);
    vec4 target    = giParams.projInverse * vec4(d.x, d.y, 1, 1);
    vec4 direction = normalize(giParams.viewInverse * vec4(normalize(target.xyz), 0));

    vec3 indirectColor = vec3(0.f, 0.f, 0.f);

    IndirectRayPayload dirPayload =  shootIndirectRay(origin.xyz, direction.xyz);

    float objIDf = dirPayload.worldNormGeometryXYZ_ObjectId.w;

    if (objIDf >= 0.)
	{
        const vec3 wo = -direction.xyz;
        vec3 shading_nrm = unpackWorldNormShading_IndirectRayPayload(dirPayload);
        vec3 geometry_nrm = unpackWorldNormGeometry_IndirectRayPayload(dirPayload);
        if (dot(geometry_nrm, wo) <= 0.)
            geometry_nrm = -geometry_nrm;
        if (dot(geometry_nrm, shading_nrm) <= 0)
            shading_nrm = -shading_nrm;

        vec3 worldPos = unpackWorldPos_IndirectRayPayload(dirPayload);
        vec3 worldNorm = shading_nrm;
        vec2 uvCoord = unpackUV_IndirectRayPayload(dirPayload);

        // Initialize a random seed, per-pixel, based on a screen position and temporally varying count
	    uint randSeed = initRand(gl_LaunchIDEXT.x + gl_LaunchIDEXT.y * gl_LaunchSizeEXT.x, giParams.frameCount);

        DirectInputData inputData = packDirectInputData(objIDf, worldPos.xyz, worldNorm, uvCoord);

        // Reservoir reminder:
        // .x: weight sum
        // .y: chosen light for the pixel
        // .z: the number of samples seen for this current light
        // .w: the final adjusted weight for the current pixel following the formula in algorithm 3 (r.W)        

        vec4 reservoir = vec4(0.f, 0.f, 0.f, 0.f);
        float p_hat;

        uint lightToSample = 1;
        float shadowColor = 0.f;

		// Generate Initial Candidates
		for (int i = 0; i < min(giParams.lightsCount, 32); i++) {
            lightToSample = min( uint(nextRand(randSeed) * giParams.lightsCount),
                        giParams.lightsCount - 1u );

            DirectOutputData outputCurrentData = ggxDirect(lightToSample, inputData, giParams.camPos.xyz, false);

            // p_hat of the light is f * Le * G / pdf
            p_hat = length(unpackLo_DirectOutputData(outputCurrentData));
            reservoir = updateReservoir(randSeed, reservoir, lightToSample, p_hat);
		};

		// Evaluate visibility for initial candidate and set r.W value
		lightToSample = uint(reservoir.y);
        DirectOutputData outputCurrentData = ggxDirect(lightToSample, inputData, giParams.camPos.xyz, false);

        // p_hat of the light is f * Le * G / pdf
        p_hat = length(unpackLo_DirectOutputData(outputCurrentData));
		reservoir.w = (1.f / max(p_hat, 0.0001f)) * (reservoir.x / max(reservoir.z, 0.0001f));

        {
            SLight lightInfo = lightsBuffer.lights[lightToSample];

            vec3 lightDir = lightInfo.position.xyz - worldPos.xyz;
            // Avoid NaN
            float distSquared = dot(lightDir, lightDir);
            float lightDistance = (distSquared > 1e-5f) ? length(lightDir) : 0.f;
            lightDir = (distSquared > 1e-5f) ? normalize(lightDir) : vec3(0.f, 0.f, 0.f);

            float shadowColor = shadowRayVisibility(worldPos.xyz, lightDir, lightDistance, giParams.shadowMult);
            if (shadowColor < 0.001f) {
                reservoir.w = 0.f;
            }
        }

        vec4 prev_reservoir = vec4(0.f, 0.f, 0.f, 0.f);

        vec4 screen_space = giParams.prevProjView * vec4(worldPos, 1.);
        screen_space /= screen_space.w;
        vec2 prevIndex = vec2(gl_LaunchIDEXT.xy);
        prevIndex.x = ((screen_space.x + 1.f) / 2.f) * gl_LaunchSizeEXT.x;
        prevIndex.y = ((1.f - screen_space.y) / 2.f) * gl_LaunchSizeEXT.y;

        if (prevIndex.x >= 0 && prevIndex.x < gl_LaunchSizeEXT.x && prevIndex.y >= 0 && prevIndex.y < gl_LaunchSizeEXT.y) {
            prev_reservoir = texture(reservoirPrev, uv).rgba;
        }
        //Temporal reuse
        {
            vec4 temporal_reservoir = vec4(0.f, 0.f, 0.f, 0.f);
			// combine current reservoir
            uint lightToSample = uint(reservoir.y);
			temporal_reservoir = updateReservoir(randSeed, temporal_reservoir, lightToSample, p_hat * reservoir.w * reservoir.z);

            lightToSample = uint(prev_reservoir.y);
            outputCurrentData = ggxDirect(lightToSample, inputData, giParams.camPos.xyz, false);
            // p_hat of the light is f * Le * G / pdf
            p_hat = length(unpackLo_DirectOutputData(outputCurrentData));
            prev_reservoir.z = min(20.f * reservoir.z, prev_reservoir.z);    
            temporal_reservoir = updateReservoir(randSeed, temporal_reservoir, lightToSample, p_hat * prev_reservoir.w * prev_reservoir.z);

            // set M value
			temporal_reservoir.z = reservoir.z + prev_reservoir.z;

			// set W value
            lightToSample = uint(temporal_reservoir.y);
            outputCurrentData = ggxDirect(lightToSample, inputData, giParams.camPos.xyz, false);
            // p_hat of the light is f * Le * G / pdf
            p_hat = length(unpackLo_DirectOutputData(outputCurrentData));
			temporal_reservoir.w = (1.f / max(p_hat, 0.0001f)) * (temporal_reservoir.x / max(temporal_reservoir.z, 0.0001f));

			// set current reservoir to the combined temporal reservoir
			reservoir = temporal_reservoir;
        }

        imageStore(reservoirCurr, ivec2(gl_LaunchIDEXT.xy), reservoir);

        //DRAW WITH ReSTIR result
        // {
        //     lightToSample = uint(reservoir.y);
        //     DirectOutputData outputCurrentData = ggxDirect(lightToSample, inputData, giParams.camPos.xyz, true);
        //     indirectColor += float(giParams.lightsCount) * unpackLo_DirectOutputData(outputCurrentData) * reservoir.w;
        // }

        uint INDIRECT_BOUND = giParams.numRays;
        //INDIRECT ILLUMINATION
        for (int i = 0; i < INDIRECT_BOUND; i++)
        {   

            vec3 outputCurrentData_worldNorm = unpackWorldNorm_DirectOutputData(outputCurrentData);
            float outputCurrentData_roughness = unpackRoughness_DirectOutputData(outputCurrentData);
            float outputCurrentData_metalness = unpackMetalness_DirectOutputData(outputCurrentData);
            vec3 outputCurrentData_albedo = unpackAlbedo_DirectOutputData(outputCurrentData);
            vec3 outputCurrentData_F0 = unpackF0_DirectOutputData(outputCurrentData);

            vec3 viewDir = normalize(giParams.camPos.xyz - worldPos.xyz);
            vec3 H = getGGXMicrofacet(randSeed, outputCurrentData_roughness, outputCurrentData_worldNorm);

            vec3 R = normalize(2.f * dot(viewDir, H) * H - viewDir);

            IndirectRayPayload indirPayload =  shootIndirectRay(worldPos.xyz, R);

            // Check to make sure our randomly selected, normal mapped diffuse ray didn't go below the surface
            if (dot(outputCurrentData_worldNorm, R) < 0)
                break;

            int objectId = unpackObjID_IndirectRayPayload(indirPayload);
            if (objectId <= 0)
            {
                //hit miss
                const float MAX_REFLECTION_LOD = 9;
                vec3 prefilteredColor = textureLod(prefilteredMap, R,  outputCurrentData_roughness * MAX_REFLECTION_LOD).rgb;

                float NdotV = max(dot(outputCurrentData_worldNorm, viewDir), 0.0);

                // ambient lighting (we now use IBL as the ambient term)
                vec3 kS = fresnelSchlickRoughness(NdotV, outputCurrentData_F0, outputCurrentData_roughness);
                vec2 envBRDF  = texture(brdfLUT, vec2(NdotV, outputCurrentData_roughness)).rg;
                vec3 specular = prefilteredColor * (kS * envBRDF.x + envBRDF.y);
                vec3 kD = 1.0 - kS;
                kD *= 1.0 - outputCurrentData_metalness;	  
                vec3 irradiance = texture(irradianceMap, outputCurrentData_worldNorm).rgb;
                vec3 diffuse      = irradiance * outputCurrentData_albedo;
                vec3 ambient = (kD * diffuse + specular);

                indirectColor += ambient;

                break;
            }
            else
            {
                //closest hit               
                const vec3 wo = -R;
                vec3 shading_nrm = unpackWorldNormShading_IndirectRayPayload(indirPayload);
                vec3 geometry_nrm = unpackWorldNormGeometry_IndirectRayPayload(indirPayload);
                if (dot(geometry_nrm, wo) <= 0.)
                    geometry_nrm = -geometry_nrm;
                if (dot(geometry_nrm, shading_nrm) <= 0)
                    shading_nrm = -shading_nrm;

                DirectInputData input2Data = packDirectInputData(objectId,
                    unpackWorldPos_IndirectRayPayload(indirPayload), 
                    shading_nrm, 
                    unpackUV_IndirectRayPayload(indirPayload));

                DirectOutputData outputBoundData = ggxDirect(lightToSample, input2Data, giParams.camPos.xyz, true);

                // Compute some dot products needed for shading
                float  NdotR = clamp(dot(outputCurrentData_worldNorm, R), 0.f, 1.f);
                float  NdotV = clamp(dot(outputCurrentData_worldNorm, viewDir), 0.f, 1.f);

                float  NdotH = clamp(dot(outputCurrentData_worldNorm, H), 0.f, 1.f);
                float  RdotH = clamp(dot(R, H), 0.f, 1.f);

                // What's the probability of sampling vector H from getGGXMicrofacet()?
                float  D = ggxNormalDistribution(NdotH, outputCurrentData_roughness);          // The GGX normal distribution
                float  ggxProb = D * NdotH / (4.f * RdotH);

                // Evaluate our BRDF using a microfacet BRDF model
                float  G = IndirectGeometrySmith(outputCurrentData_worldNorm, viewDir, R, outputCurrentData_roughness);   // Use Schlick's masking term approx
                vec3 F = fresnelSchlick(RdotH, outputCurrentData_F0);  // Use Schlick's approx to Fresnel
                vec3 ggxTerm = D * G * F / (4.f * NdotR * NdotV + 0.001); // The Cook-Torrance microfacet BRDF

                vec3 kS = F;
                vec3 kD = 1.0 - kS;
                kD *= 1.0 - outputCurrentData_metalness;
                indirectColor +=  NdotR * float(giParams.lightsCount) * unpackLo_DirectOutputData(outputBoundData) * (kD *outputCurrentData_albedo * M_INV_PI + ggxTerm) / max(1e-3, ggxProb);

                //for next bound
                worldPos.xyz = unpackWorldPos_IndirectRayPayload(indirPayload);
                outputCurrentData = outputBoundData;               
            }
        }
	}
    else
    {
        indirectColor = texture(prefilteredMap, direction.xyz).rgb;
    }


    imageStore(indirectOutput, ivec2(gl_LaunchIDEXT.xy), vec4(indirectColor, 1.0f));
}
