#version 460
#extension GL_EXT_ray_tracing : require
#extension GL_EXT_nonuniform_qualifier:enable
#extension GL_GOOGLE_include_directive : enable

#include "gi_raytrace.h"

layout(location = 0) rayPayloadEXT IndirectRayPayload indirectRpl;
layout(location = 1) rayPayloadEXT AORayPayload aoRpl;

layout(set = 0, binding = 1) uniform sampler2D texSet[];
layout(set = 0, binding = 2) uniform accelerationStructureEXT topLevelAS;

layout(set = 1, binding = 0) uniform _GlobalGIParams { SGlobalGIParams giParams; };

layout(set = 1, binding = 1) readonly buffer _Lights{

	SLight lights[];
} lightsBuffer;

layout(set = 1, binding = 2) readonly buffer ObjectBuffer{

	SObjectData objects[];
} objectBuffer;

layout(set = 2, binding = 0, rgba32f) uniform image2D indirectOutput;

layout(set = 3, binding = 0) uniform sampler2D wposTex;
layout(set = 3, binding = 1) uniform sampler2D normalTex;
layout(set = 3, binding = 2) uniform sampler2D uvTex;
layout(set = 3, binding = 3) uniform sampler2D objIDTex;
layout(set = 3, binding = 4) uniform samplerCube irradianceMap;
layout(set = 3, binding = 5) uniform samplerCube prefilteredMap;
layout(set = 3, binding = 6) uniform sampler2D   brdfLUT;


#include "gi_raytrace_func.h"

void main() 
{
    const vec2 uv = vec2(gl_LaunchIDEXT.xy)/vec2(gl_LaunchSizeEXT.xy);
    vec4 worldPos = texture(wposTex, uv).rgba;
    vec3 worldNorm = normalize(texture(normalTex, uv).rgb);

    vec3 indirectColor = vec3(0.f, 0.f, 0.f);

    if (worldPos.w != 0.0f)
	{
        float objIDf = texture(objIDTex, uv).r;
        vec2 gbufferTexCoord = texture(uvTex, uv).rg;   

        // Initialize a random seed, per-pixel, based on a screen position and temporally varying count
	    uint randSeed = initRand(gl_LaunchIDEXT.x + gl_LaunchIDEXT.y * gl_LaunchSizeEXT.x, giParams.frameCount);

        DirectInputData inputData = packDirectInputData(objIDf, worldPos.xyz, worldNorm, gbufferTexCoord);

        vec4 reservoir = vec4(0.f, 0.f, 0.f, 0.f);
        float p_hat;

        uint lightToSample = 1;
        float shadowColor = 0.f;

		// Generate Initial Candidates - Algorithm 3 of ReSTIR paper
		for (int i = 0; i < min(giParams.lightsCount, 32); i++) {
            lightToSample = max( 1u, min( uint(nextRand(randSeed) * giParams.lightsCount),
                        giParams.lightsCount - 1u ));

            DirectOutputData outputCurrentData = ggxDirect(lightToSample, inputData, giParams.camPos.xyz, shadowColor);

            vec4 reservoir = vec4(0.f, 0.f, 0.f, 0.f);
            float p_hat;
            // p_hat of the light is f * Le * G / pdf
            p_hat = length(unpackLo_DirectOutputData(outputCurrentData));
            reservoir = updateReservoir(randSeed, reservoir, lightToSample, p_hat);
		};

		// Evaluate visibility for initial candidate and set r.W value
		lightToSample = uint(reservoir.y);
        DirectOutputData outputCurrentData = ggxDirect(lightToSample, inputData, giParams.camPos.xyz, shadowColor);

        // p_hat of the light is f * Le * G / pdf
        p_hat = length(unpackLo_DirectOutputData(outputCurrentData));
		reservoir.w = (1.f / max(p_hat, 0.0001f)) * (reservoir.x / max(reservoir.z, 0.0001f));

		if (shadowColor < 0.001f) {
			reservoir.w = 0.f;
		}

       indirectColor = float(giParams.lightsCount) * unpackLo_DirectOutputData(outputCurrentData);

        uint INDIRECT_BOUND = giParams.numRays;
        //INDIRECT ILLUMINATION
        for (int i = 0; i < INDIRECT_BOUND; i++)
        {   

            vec3 outputCurrentData_worldNorm = unpackWorldNorm_DirectOutputData(outputCurrentData);
            float outputCurrentData_roughness = unpackRoughness_DirectOutputData(outputCurrentData);
            float outputCurrentData_metalness = unpackMetalness_DirectOutputData(outputCurrentData);
            vec3 outputCurrentData_albedo = unpackAlbedo_DirectOutputData(outputCurrentData);
            vec3 outputCurrentData_F0 = unpackF0_DirectOutputData(outputCurrentData);

            vec3 viewDir = normalize(giParams.camPos.xyz - worldPos.xyz);
            vec3 H = getGGXMicrofacet(randSeed, outputCurrentData_roughness, outputCurrentData_worldNorm);

            vec3 R = normalize(2.f * dot(viewDir, H) * H - viewDir);

            IndirectRayPayload indirPayload =  shootIndirectRay(worldPos.xyz, R);

            // Check to make sure our randomly selected, normal mapped diffuse ray didn't go below the surface
            if (dot(outputCurrentData_worldNorm, R) < 0)
                break;

            int objectId = unpackObjID_IndirectRayPayload(indirPayload);
            if (objectId <= 0)
            {
                //hit miss
                const float MAX_REFLECTION_LOD = 9;
                vec3 prefilteredColor = textureLod(prefilteredMap, R,  outputCurrentData_roughness * MAX_REFLECTION_LOD).rgb;

                float NdotV = max(dot(outputCurrentData_worldNorm, viewDir), 0.0);

                // ambient lighting (we now use IBL as the ambient term)
                vec3 kS = fresnelSchlickRoughness(NdotV, outputCurrentData_F0, outputCurrentData_roughness);
                vec2 envBRDF  = texture(brdfLUT, vec2(NdotV, outputCurrentData_roughness)).rg;
                vec3 specular = prefilteredColor * (kS * envBRDF.x + envBRDF.y);
                vec3 kD = 1.0 - kS;
                kD *= 1.0 - outputCurrentData_metalness;	  
                vec3 irradiance = texture(irradianceMap, outputCurrentData_worldNorm).rgb;
                vec3 diffuse      = irradiance * outputCurrentData_albedo;
                vec3 ambient = (kD * diffuse + specular);

                indirectColor += ambient;

                break;
            }
            else
            {
                //closest hit               
                const vec3 wo = -R;
                vec3 shading_nrm = unpackWorldNormShading_IndirectRayPayload(indirPayload);
                vec3 geometry_nrm = unpackWorldNormGeometry_IndirectRayPayload(indirPayload);
                if (dot(geometry_nrm, wo) <= 0.)
                    geometry_nrm = -geometry_nrm;
                if (dot(geometry_nrm, shading_nrm) <= 0)
                    shading_nrm = -shading_nrm;

                DirectInputData input2Data = packDirectInputData(objectId,
                    unpackWorldPos_IndirectRayPayload(indirPayload), 
                    shading_nrm, 
                    unpackUV_IndirectRayPayload(indirPayload));

                DirectOutputData outputBoundData = ggxDirect(lightToSample, input2Data, giParams.camPos.xyz,shadowColor);

                // Compute some dot products needed for shading
                float  NdotR = clamp(dot(outputCurrentData_worldNorm, R), 0.f, 1.f);
                float  NdotV = clamp(dot(outputCurrentData_worldNorm, viewDir), 0.f, 1.f);

                float  NdotH = clamp(dot(outputCurrentData_worldNorm, H), 0.f, 1.f);
                float  RdotH = clamp(dot(R, H), 0.f, 1.f);

                // What's the probability of sampling vector H from getGGXMicrofacet()?
                float  D = ggxNormalDistribution(NdotH, outputCurrentData_roughness);          // The GGX normal distribution
                float  ggxProb = D * NdotH / (4.f * RdotH);

                // Evaluate our BRDF using a microfacet BRDF model
                float  G = IndirectGeometrySmith(outputCurrentData_worldNorm, viewDir, R, outputCurrentData_roughness);   // Use Schlick's masking term approx
                vec3 F = fresnelSchlick(RdotH, outputCurrentData_F0);  // Use Schlick's approx to Fresnel
                vec3 ggxTerm = D * G * F / (4.f * NdotR * NdotV + 0.001); // The Cook-Torrance microfacet BRDF

                vec3 kS = F;
                vec3 kD = 1.0 - kS;
                kD *= 1.0 - outputCurrentData_metalness;
                indirectColor +=  NdotR * float(giParams.lightsCount) * unpackLo_DirectOutputData(outputBoundData) * (kD *outputCurrentData_albedo * M_INV_PI + ggxTerm) / max(1e-3, ggxProb);

                //for next bound
                worldPos.xyz = unpackWorldPos_IndirectRayPayload(indirPayload);
                outputCurrentData = outputBoundData;               
            }
        }
	}
    else
    {
        const vec2 pixelCenter = vec2(gl_LaunchIDEXT.xy) + vec2(0.5);
        const vec2 inUV = pixelCenter/vec2(gl_LaunchSizeEXT.xy);
        vec2 d = inUV * 2.0 - 1.0;

        vec4 target    = giParams.projInverse * vec4(d.x, d.y, 1, 1);
        vec4 direction = giParams.viewInverse * vec4(normalize(target.xyz), 0);
        vec3 dir = normalize(direction.xyz);
        indirectColor = texture(prefilteredMap, dir).rgb;
    }


    imageStore(indirectOutput, ivec2(gl_LaunchIDEXT.xy), vec4(indirectColor, 1.0f));
}
